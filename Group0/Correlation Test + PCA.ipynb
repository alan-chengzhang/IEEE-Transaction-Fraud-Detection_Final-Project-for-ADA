{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statistics\n",
    "import math\n",
    "import datetime\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data processed with correlation test but still with missing data\n",
    "os.chdir(\"/Users/liweizhang/Columbia_University/cu_semester2/GitHub/ADA-Project-LoVEWtc/Group0/\")\n",
    "data = pd.read_csv(\"train_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_20</th>\n",
       "      <th>id_28</th>\n",
       "      <th>id_29</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>4</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2987005</td>\n",
       "      <td>0</td>\n",
       "      <td>86510</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5937</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2987006</td>\n",
       "      <td>0</td>\n",
       "      <td>86522</td>\n",
       "      <td>159.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12308</td>\n",
       "      <td>360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2987007</td>\n",
       "      <td>0</td>\n",
       "      <td>86529</td>\n",
       "      <td>422.5</td>\n",
       "      <td>4</td>\n",
       "      <td>12695</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2987008</td>\n",
       "      <td>0</td>\n",
       "      <td>86535</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2803</td>\n",
       "      <td>100.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2987009</td>\n",
       "      <td>0</td>\n",
       "      <td>86536</td>\n",
       "      <td>117.0</td>\n",
       "      <td>4</td>\n",
       "      <td>17399</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt  ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5          4  13926   \n",
       "1        2987001        0          86401            29.0          4   2755   \n",
       "2        2987002        0          86469            59.0          4   4663   \n",
       "3        2987003        0          86499            50.0          4  18132   \n",
       "4        2987004        0          86506            50.0          1   4497   \n",
       "5        2987005        0          86510            49.0          4   5937   \n",
       "6        2987006        0          86522           159.0          4  12308   \n",
       "7        2987007        0          86529           422.5          4  12695   \n",
       "8        2987008        0          86535            15.0          1   2803   \n",
       "9        2987009        0          86536           117.0          4  17399   \n",
       "\n",
       "   card2  card3  card4  card5  ...  id_20  id_28  id_29  id_31  id_35  id_36  \\\n",
       "0    NaN  150.0      1  142.0  ...    NaN     -1     -1     -1     -1     -1   \n",
       "1  404.0  150.0      2  102.0  ...    NaN     -1     -1     -1     -1     -1   \n",
       "2  490.0  150.0      3  166.0  ...    NaN     -1     -1     -1     -1     -1   \n",
       "3  567.0  150.0      2  117.0  ...    NaN     -1     -1     -1     -1     -1   \n",
       "4  514.0  150.0      2  102.0  ...  144.0      1      1    123      1      0   \n",
       "5  555.0  150.0      3  226.0  ...    NaN     -1     -1     -1     -1     -1   \n",
       "6  360.0  150.0      3  166.0  ...    NaN     -1     -1     -1     -1     -1   \n",
       "7  490.0  150.0      3  226.0  ...    NaN     -1     -1     -1     -1     -1   \n",
       "8  100.0  150.0      3  226.0  ...  500.0      1      1     98      1      0   \n",
       "9  111.0  150.0      2  224.0  ...    NaN     -1     -1     -1     -1     -1   \n",
       "\n",
       "   id_37  id_38  DeviceType  DeviceInfo  \n",
       "0     -1     -1          -1          -1  \n",
       "1     -1     -1          -1          -1  \n",
       "2     -1     -1          -1          -1  \n",
       "3     -1     -1          -1          -1  \n",
       "4      1      1           1         954  \n",
       "5     -1     -1          -1          -1  \n",
       "6     -1     -1          -1          -1  \n",
       "7     -1     -1          -1          -1  \n",
       "8      0      1           1        1727  \n",
       "9     -1     -1          -1          -1  \n",
       "\n",
       "[10 rows x 272 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple imputation to fill missing data\n",
    "def multiple_linear_fit(df,replicates):\n",
    "    for columns in list(df.columns):\n",
    "        #if not isinstance(df[columns][0],str):\n",
    "        if columns  not in ['dist1' ,'dist2' ,'card2'] and columns[0] !='D':\n",
    "            df[columns].fillna(df[columns].mode()[0],inplace = True)\n",
    "    complete_cols_df = df[df.columns[df.isna().sum() == 0].tolist()]\n",
    "    #complete_cols_df = complete_cols_df.drop( [x for x in complete_cols_df.columns if isinstance(complete_cols_df[x][0],str)],axis = 1 )\n",
    "    uncomplete_cols = df.columns[df.isna().any()].tolist()\n",
    "    for col in uncomplete_cols:\n",
    "        complete_cols_df[col] = df[col]\n",
    "        known_part = complete_cols_df[complete_cols_df[col].notna()].as_matrix()\n",
    "        unknown_part = complete_cols_df[complete_cols_df[col].isna()].as_matrix()\n",
    "        y = known_part[:, -1]\n",
    "        X = known_part[:,0:complete_cols_df.shape[1]-2]\n",
    "        \n",
    "        lrg = LinearRegression()\n",
    "        #print(X, y)\n",
    "        lrg.fit(X, y)\n",
    "        cnt = 0\n",
    "        predictedAges = lrg.predict(unknown_part[:,0:complete_cols_df.shape[1]-2])\n",
    "        for cnt in range(0,replicates-1):\n",
    "            predictedAges += lrg.predict(unknown_part[:,0:complete_cols_df.shape[1]-2])\n",
    "            cnt += 1\n",
    "        df.loc[ (df[col].isna()), col ] = predictedAges/replicates\n",
    "        complete_cols_df[col] = df[col]\n",
    "    return df\n",
    "\n",
    "data2 = multiple_linear_fit(data,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No missing data\n",
    "data3.isnull().values.any() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_X = data3.loc[:, data3.columns != 'isFraud']\n",
    "data_y = data3['isFraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_X,\n",
    "    data_y,\n",
    "    test_size=0.25,\n",
    "    random_state=42)\n",
    "\n",
    "sc = StandardScaler() #feature scaling\n",
    "  \n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "pca = PCA(.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "smote = SMOTE(ratio='minority')\n",
    "X_sm, y_sm = smote.fit_sample(X_train_pca, y_train)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_sm, y_sm)\n",
    "predictions = lr.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score is  0.19120985638854168\n",
      "Precision 0.11056699510295592\n",
      "Recall is  0.7065032987747408\n",
      "AUC is  0.7473358199768456\n"
     ]
    }
   ],
   "source": [
    "print('F1-score is ',f1_score(y_test,predictions))\n",
    "print('Precision',metrics.precision_score(y_test,predictions))\n",
    "print('Recall is ',recall_score(y_test, predictions))\n",
    "print('AUC is ',roc_auc_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score is  0.282591725214676\n",
      "Precision 0.8227272727272728\n",
      "Recall is  0.1705937794533459\n",
      "AUC is  0.5846118619742666\n"
     ]
    }
   ],
   "source": [
    "#without smote\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_pca, y_train)\n",
    "predictions2 = lr2.predict(X_test_pca)\n",
    "\n",
    "print('F1-score is ',f1_score(y_test,predictions2))\n",
    "print('Precision',metrics.precision_score(y_test,predictions2))\n",
    "print('Recall is ',recall_score(y_test, predictions2))\n",
    "print('AUC is ',roc_auc_score(y_test,predictions2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
